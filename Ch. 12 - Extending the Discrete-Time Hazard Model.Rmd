---
title: "Chapter 12 - Extending the Discrete-Time Hazard Model"
output: html_notebook
---

# Alternative Specifications for the "Main Effect of TIME"

Ideally, your specification for TIME in the discrete-time hazard model should be motivated by a combination of theory, previous research, and exploratory analysis. Serious consideration of alternatives to the completely general approach to time is essential when:

1. Your study involves many discrete time periods. 
2. Hazard is expected to be near zero in some time periods. 
3. Some time periods have small risk sets. 

## An Ordered Series of Polynomial Specifications for TIME

```{r}
library(tidyverse)

tenure.pp <- 
  read_csv("data/tenure_pp.csv") %>%
  rename_all(tolower)

glimpse(tenure.pp)

# count total number of records
tenure.pp %>%
  distinct(id) %>%
  count()

# count censored cases
tenure.pp %>%
  group_by(id) %>%
  arrange(desc(period)) %>%
  slice(1) %>%
  ungroup() %>%
  count(event) %>%
  mutate(percent = 100 * n / sum(n))
```

94 (36%) were censored. 

```{r}
library(brms)
library(cmdstanr)
```

Fit all 7 models in talbe 12.2.

```{r}
tenure.pp <- 
  tenure.pp %>%
  mutate(period_f = factor(period))

# constant
fit12.1 <- 
  brm(event ~ 1,
      family = bernoulli(link = "logit"),
      prior = prior(normal(0, 4), class = Intercept),
      data = tenure.pp,
      cores = 4, 
      backend = "cmdstanr")

# linear
fit12.2 <- 
  brm(event ~ 0 + Intercept + period,
      family = bernoulli(link = "logit"),
      prior = prior(normal(0, 4), class = b),
      data = tenure.pp,
      cores = 4, 
      backend = "cmdstanr")

# quadratic
fit12.3 <- 
  brm(event ~ 0 + Intercept + period + I(period^2),
      family = bernoulli(link = "logit"),
      prior = prior(normal(0, 4), class = b),
      data = tenure.pp,
      cores = 4, 
      backend = "cmdstanr")

# cubic
fit12.4 <- 
  brm(event ~ 0 + Intercept + period + I(period^2) + I(period^3),
      family = bernoulli(link = "logit"),
      prior = prior(normal(0, 4), class = b),
      data = tenure.pp,
      cores = 4, 
      backend = "cmdstanr")

# fourth order
fit12.5 <- 
  brm(event ~ 0 + Intercept + period + I(period^2) + I(period^3) + I(period^4),
      family = bernoulli(link = "logit"),
      prior = prior(normal(0, 4), class = b),
      data = tenure.pp,
      cores = 4, 
      backend = "cmdstanr")

# fifth order
fit12.6 <- 
  brm(event ~ 0 + Intercept + period + I(period^2) + I(period^3) + I(period^4) + I(period^5),
      family = bernoulli(link = "logit"),
      prior = prior(normal(0, 4), class = b),
      data = tenure.pp,
      cores = 4, 
      backend = "cmdstanr")

# general
fit12.7 <- 
  brm(event ~ 0 + d1 + d2 + d3 + d4 + d5 + d6 + d7 + d8 + d9,
      family = bernoulli(link = "logit"),
      prior = prior(normal(0, 4), class = b),
      data = tenure.pp,
      cores = 4, 
      backend = "cmdstanr")

# general with `factor(period)
fit12.8 <- 
  brm(event ~ 0 + period_f,
      family = bernoulli(link = "logit"),
      prior = prior(normal(0, 4), class = b),
      data = tenure.pp,
      cores = 4, 
      backend = "cmdstanr")
```

Now plot the hazard functions.

```{r}
p1 <-
  tibble(period = 1:9) %>% 
  ggplot(aes(x = period)) +
  geom_ribbon(aes(ymin = fixef(fit12.1)[, 3] %>% inv_logit_scaled(),
                  ymax = fixef(fit12.1)[, 4] %>% inv_logit_scaled()),
              alpha = 1/5) +
  geom_line(aes(y = fixef(fit12.1)[, 1] %>% inv_logit_scaled()),
            size = 1, color = "blue1") +
  ggtitle("constant") +
  ylab("event | trials(1)")

p2 <- plot(conditional_effects(fit12.2), plot = F)[[1]] + ggtitle("linear")
p3 <- plot(conditional_effects(fit12.3), plot = F)[[1]] + ggtitle("quadratic")
p4 <- plot(conditional_effects(fit12.4), plot = F)[[1]] + ggtitle("cubic")
p5 <- plot(conditional_effects(fit12.5), plot = F)[[1]] + ggtitle("fourth order")
p6 <- plot(conditional_effects(fit12.6), plot = F)[[1]] + ggtitle("fifth order")
p7 <- plot(conditional_effects(fit12.8), 
           cat_args = list(size = 3/2), 
           plot = F)[[1]] + ggtitle("general")

library(patchwork)

(((p1 + p2 + p3 + p4 + p5 + p6) & scale_x_continuous(breaks = 1:9)) + p7) &
  coord_cartesian(ylim = c(0, .5)) &
  theme(panel.grid = element_blank())
```

Model comparison with WAIC and LOO.

```{r}
fit12.1 <- add_criterion(fit12.1, c("loo", "waic"))
fit12.2 <- add_criterion(fit12.2, c("loo", "waic"))
fit12.3 <- add_criterion(fit12.3, c("loo", "waic"))
fit12.4 <- add_criterion(fit12.4, c("loo", "waic"))
fit12.5 <- add_criterion(fit12.5, c("loo", "waic"))
fit12.6 <- add_criterion(fit12.6, c("loo", "waic"))
fit12.7 <- add_criterion(fit12.7, c("loo", "waic"))
fit12.8 <- add_criterion(fit12.8, c("loo", "waic"))

# loo
loo_compare(fit12.1, fit12.2, fit12.3, fit12.4, fit12.5, fit12.6, fit12.7, 
            criterion = "loo") %>% 
  print(simplify = F)

# WAIC

loo_compare(fit12.1, fit12.2, fit12.3, fit12.4, fit12.5, fit12.6, fit12.7, 
            criterion = "waic") %>% 
  print(simplify = F)
```

## Criteria for Comparing Alternative Specifications

Compare models:

```{r}
# the constant and linear models
l1 <- loo_compare(fit12.1, fit12.2, criterion = "loo")

# the linear and quadratic models
l2 <- loo_compare(fit12.2, fit12.3, criterion = "loo")

# the quadratic and general models
l3 <- loo_compare(fit12.3, fit12.7, criterion = "loo")

l1 %>% print(simplify = F)
l2 %>% print(simplify = F)
l3 %>% print(simplify = F)
```

Instead of picking a single model as the best, we can use model averaging. 

```{r}
nd <- tibble(period = 1:9)

pp <- 
  pp_average(fit12.3, fit12.4,
             weights = "loo",
             newdata = nd,
             method = "pp_expect") %>%
  data.frame() %>%
  bind_cols(nd)

# hazard
p1 <-
  pp %>% 
  ggplot(aes(x = period)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              alpha = 1/5) +
  geom_line(aes(y = Estimate)) +
  scale_x_continuous("Years after hire", breaks = 0:9, limits = c(0, 9)) +
  ylab("hazard") +
  theme(panel.grid = element_blank())

# survival
p2 <-
  pp %>% 
  select(-Est.Error) %>% 
  bind_rows(tibble(Estimate = 0, Q2.5 = 0, Q97.5 = 0, period = 0)) %>% 
  arrange(period) %>% 
  mutate_at(vars(Estimate:Q97.5), .funs = ~ cumprod(1 - .)) %>% 
  
  ggplot(aes(x = period)) +
  geom_hline(yintercept = .5, color = "white") +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              alpha = 1/5) +
  geom_line(aes(y = Estimate)) +
  scale_x_continuous("Years after hire", breaks = 0:9) +
  scale_y_continuous("survival", breaks = c(0, .5, 1), limits = c(0, 1)) +
  theme(panel.grid = element_blank())

# combine
(p1 | p2) + 
  plot_annotation(title = "Behold the fitted hazard and survival curves based on a weighted\naverage of the quadratic and cubic models!")
```

## Interpreting Parameters from Linear, Quadratic, and Cubic Specifications

With the simplest specification, the linear model, the intercept represents the value of the outcome when the predictor is 0. As the predictor in this model is $TIME - c$, the intercept represents the value of the logit hazard in time period $c$. The slope parameter is unaffected by the subtraction of $c$. It represents the increase (or decrease) in logit hazard per unit difference in TIME. 

In the quadratic specification, the intercept still measures the value of logit hazard in time period $c$. The slope parameter still measures the increase (or decrease) in logit hazard per unit of TIME, but only at one particular instant, time $c$. 

```{r}
tenure.pp <-
  tenure.pp %>% 
  mutate(period_5 = period - 5)

# how do the two `period` variables compare?
tenure.pp %>% 
  distinct(period, period_5)

fit12.9 <-
  update(fit12.3,
         newdata = tenure.pp,
         event ~ 0 + Intercept + period_5 + I(period_5^2),
         chains = 4, cores = 4, iter = 2000, warmup = 1000,
         backend = "cmdstan")
print(fit12.9)
```

# Using the Complementary Log-Log Link to Specify a Discrete-Time Hazard Model

The clog-log transformation maps the probabilities onto a new scale with no upper or lower bound and yields the logarithm of the negated logarithm of the probability of event occurrence. 

## The Clog-Log Transformation: When and Why It Is Useful

* The distance between pairs of values on the clog-log scale per unit difference in hazard probability get consistently smaller at higher values of hazard. 
* It is asymmetric
* It provides a discrete-time statistical model for hazard that has a built-in proportional hazards assumption, and not a proportional odds assumption. This provides a conceptual parallelism between the clog-log discrete-time hazard model and the models that we will ultimatly describe for continuous-time survival analysis

## A Discrete-Time Hazard Model Using the Complementary Log-Log Link

With the clog-log we assume:

1. for each combination of predictor values, there is a postulated clog-log hazard function
2. each of these clog-log hazard functions has an identical shape
3. the distance between each of these clog-log hazard functions is identical in every time period

The exponential of the parameter estimate gives the hazard ratio.

## Choosing between Logit and Clog-log Links for Discrete-Time Hazard Models


# Time-Varying Predictors

## Assumptions Underlying a Model with Time-Varying Predictors

```{r}
depression.pp <- 
  read_csv("data/depression_pp.csv") %>% 
  # convert the column names to lower case
  rename_all(tolower)

glimpse(depression.pp)
```

In specifying a model, we make 3 assumptions about the relationship between the risk of event occurrence and the time-varying predictor:

1. For each value of the predictor in time period j, there is a postulated value of logit hazard
2. Joining consecutive postulated values of logit hazard for constant values of the time-varying predictor yields logit hazard functions with identical shapes
3. The distance between each of these logit hazard functions is identical in every time period

